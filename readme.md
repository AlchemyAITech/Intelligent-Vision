# 智能视界 (Intelligent Vision) — AI 互动教学与实验平台

## 项目简介

**智能视界 (Intelligent Vision)** 是清华大学 2026 通识课程的核心配套实验平台。不同于传统的幻灯片教学，本系统采用纯前端 **Vue 3** 驱动界面，结合 **FastAPI + PyTorch** 构建强大的高性能推理后端，为学生提供“开箱即用、所见即所得”的互动式计算机视觉学习体验。

平台将深度学习黑盒“透明化”，涵盖从基础像素操作、卷积核滤镜，到神经网络训练的“全链路观测”，再到 YOLO 检测、SAM 3 万物分割以及实时人脸识别等前沿技术的亲身实践。

---

## 🔬 六大核心实验室集群

### 1. 🎨 图像的本质 (Color Lab)
* **色彩空间漫游**: 支持原图在 RGB、HSV、YCbCr、Grayscale 之间的实时转换与解析。
* **微观像素观测**: 特有的“红框扫描”功能，能够提取指定区域 20x20 的像素矩阵，直观揭示图像的数字本质。

### 2. ⚙️ 卷积实验室 (Convolution Lab)
* **实时滤波器**: 内置边缘检测 (Sobel, Prewitt)、图像平滑 (Gaussian, Mean Blur)、锐化等 10+ 种经典卷积核。
* *New!* **⚡ 动态卷积演示**: 提供平方级加速的 **实时扫描动画引擎**，双 Canvas 同步渲染，让学生肉眼观察卷积核游走于输入图像并逐像素计算结果的物理全过程。

### 3. 🧠 神经网络实验室 (CNN Lab)
* **网络架构解剖**: 可视化构建 CNN 模型，支持动态下发训练超参 (优化器、损失函数)。
* *New!* **工业级图表追踪**: 全新的 0.2 精密步长与全量数据呈现，动态绘制极细线条的 Loss/Accuracy 双轴曲线，展现极简且专业的科研级观测感。
* **状态机托管**: 彻底重构了内部流转逻辑，支持安全中止、一键重训以及跨页面的状态驻留与自动跳转模型测试。

### 4. 👁️ YOLO 实验室 (YOLO Lab)
* **现代全能视觉**: 基于 Ultralytics 与 FastAPI 的异步通信架构。
* **三大核心子任务**:
  * **Detect (目标检测)**: 实时框选并识别多类物体。
  * **Segment (实例分割)**: 像素级分离轮廓。
  * **Pose (姿态估计)**: 精准绘制人体关键点骨架连线。

### 5. ✨ SAM 实验室 (Segment Anything)
* **SAM 3 次世代核心驱动**: 完整接入最新的 `sam3_tracking_predictor` 架构。
* *New!* **🚀 三合一全功能集群 (v2.5+)**:
  * **交互式标注 (Labeling)**: 毫秒级像素分割，支持点 (Point) 与矩形框 (Box) 灵活提示。
  * **零样本追踪 (Tracking)**: **业界领先**，只需在视频/流首帧“锚定”目标，掩码将随物体运动实时精密贴合。
  * **零样本识别 (Recognition)**: 结合分割特征与语义映射，实现对未知物体的即时分类打标。
* *New!* **🖼️ 大屏化布局统一**: 彻底移除宽度限制，对齐 **320px 专业侧边栏** 规格，提供沉浸式科研观测视野。
* **物理健壮性**: 彻底修复了 BFloat16 硬件兼容问题与环境残留上下文 (Context Scope) 泄露。


### 6. 👤 人脸实验室 (Face Lab)
* **高精度网格体系**: 基于 MediaPipe 实现单帧 478 点稀疏人脸追踪。
* **身份锚定与追踪**: 接入特征提取网络与重构的 Cosine Distance 识别算法。
* **红灯预警系统**: 实时对比人脸特征库，当检测到身份特征匹配度低于安全阈值时，自动触发视觉级警告光晕。
* *New!* **🔐 工业级命名与一致性保障 (v2.5+)**:
    * **SHA256 哈希命名**: 文件名基于图像内容生成摘要，实现“物理级去重”与零碰撞存储。
    * **全自动特征索引对齐**: 针对 `embeddings_cache.json` 实现了全生命周期管理，重命名人员、移动样本或转正陌生人时，特征索引会秒级递归同步，无需重计且永不跌落为未知。
    * **静默合并机制**: 支持在人员更名或转正时自动合并已存在的目标文件夹，实现样本流的平滑接纳。


---

## 🛠️ 技术架构演进 (v2.0+)

本项目已完成了由 Streamlit 单体架构向**云原生前后端分离架构**的史诗级重构：

### 1. 视效增强的前端基座 (Frontend)
* **Vue 3 (Composition API)**: 取代了厚重的传统模板渲染，实现状态的超高速响应流转。
* **纯净无依赖栈**: 仅引入 Axios 进行 API 数据交互，免于繁琐的 `npm install` 依赖地狱，通过 ESM (ES Modules) 在浏览器原生运行 (`index.html` → `app.js`)。
* **CSS 模块化系统**: 提炼全局色彩 Token 与毛玻璃 (Glassmorphism) 层级，界面全方位适配暗调与亮彩主题体系。

### 2. 大吞吐量的推理后端 (Backend)
* **FastAPI 引擎**: 基于 ASGI 服务器 `uvicorn` 提供极致并发性能。异步协同机制 (`async/await`) 解决了以往 CPU 密集型任务阻塞主线程的顽疾。
* **PyTorch 深度融合**: 构建了常驻内存的模型管理单例 (Singletons)，大幅缩减网络加载耗时。
* **跨平台异构计算**: 针对 Apple Silicon (M1/M2/M3 等) 及非 CUDA 设备实施了严格的回退策略，规避特定算子及 BFloat16 等精度不兼容等硬件底层问题。

---

## 🚀 极速启动指南

### 预置环境
项目包含 `.venv` 环境（预装所有依赖），确保您在 `codev2` 根目录下执行：

```bash
# 启动集成脚本 (自动绑定环境变量与端口)
./start.sh
```

*若遇到 8000 端口被占用，脚本将自动提示。您可执行 `lsof -t -i :8000 | xargs kill -9` 强制释放。*

服务拉起后，用浏览器访问 `http://127.0.0.1:8000` 即可进入实验室。

---
*版权所有 © 2026 智能视界通识课教材组*
